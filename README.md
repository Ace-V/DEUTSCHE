# DEUTSCHE
A tool that audits ML models for demographic bias in credit decisions
In this i'll try to minimize the *BIAS* in AI algorithms so that the financial decisions are made in the favour of those who are qualified for it.

# File 1 first_test,first_chart
Used the German credit dataset I got to know abput through a paper Fairness Definitions Explained By Sahil Verma and Julia Rubin I ran the python script to see firsthand if the bias is there and if it is then how much and It can seen that the differenece on the basis of gender is 7.5% which is a huge gap on a large scale 

<img width="847" height="255" alt="output 1" src="https://github.com/user-attachments/assets/8cb964bc-b9dd-4627-ba94-7ad4feb07556" />
<img width="826" height="618" alt="image" src="https://github.com/user-attachments/assets/75dc93f2-7630-4934-b7bb-1c6321daff20" />



This demonstrates violations of:
- Deutsche Bank's "Fairness & Bias" AI principle
- EU AI Act requirements for high-risk systems
- The 80% rule in anti-discrimination law

Adding multiple AIF360 metrics so that we can closely observe the Biases present 

# 1 Statistical Parity Differenece 

<img width="1156" height="195" alt="image" src="https://github.com/user-attachments/assets/2cf54d2d-dc1a-4788-8119-bfdeda00d79a" />

# 2 Disparate Impact

<img width="766" height="141" alt="image" src="https://github.com/user-attachments/assets/2dca3ef2-87e5-40b7-8471-44b17d108357" />

# 3 Equal Opportunity

<img width="1308" height="311" alt="image" src="https://github.com/user-attachments/assets/59c50e6e-2392-4a59-a167-8be11549559c" />






